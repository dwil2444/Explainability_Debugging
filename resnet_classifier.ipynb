{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e63b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from utils.helper import CleanCuda, GetDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6593cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTPATH = 'weights/resnet50.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7e8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/dw3zn/Repos/saliency_calibration/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/dw3zn/Repos/saliency_calibration/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c7efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarData():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.Resize([32, 32])\n",
    "        ])\n",
    "        self.val_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.Resize([32, 32])\n",
    "        ])\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        \"\"\"\n",
    "        Uses torchvision.datasets.ImageNet to load dataset.\n",
    "        Downloads dataset if doesn't exist already.\n",
    "        Returns:\n",
    "             torch.utils.data.TensorDataset: trainset, valset\n",
    "        \"\"\"\n",
    "\n",
    "        trainset = datasets.CIFAR100('datasets/CIFAR100/train/', train='True', transform=self.train_transforms,\n",
    "                                     target_transform=None, download=True)\n",
    "        valset = datasets.CIFAR100('datasets/CIFAR100/val/', train='False', transform=self.val_transforms,\n",
    "                                   target_transform=None, download=True)\n",
    "\n",
    "        return trainset, valset \n",
    "    \n",
    "    \n",
    "    def get_data_loader(self, batch_size=16):\n",
    "        \"\"\"\n",
    "        Uses Class Object methods to generate\n",
    "        torch dataloaders for train and val set\n",
    "        \n",
    "        param: batch_size: duh\n",
    "        \"\"\"\n",
    "        trainset, valset = self.get_dataset()\n",
    "        trainloader = DataLoader(trainset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=2,\n",
    "                            )\n",
    "        valloader = DataLoader(valset,\n",
    "                               batch_size=1,\n",
    "                               shuffle=True,)\n",
    "        return trainloader, valloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0551b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, dataloader, num_epochs=1, \n",
    "         criterion=nn.CrossEntropyLoss(), \n",
    "         ):\n",
    "    device = GetDevice()\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    running_loss = 0\n",
    "    for epoch in range(0, num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            imgs, labels = batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch == 0:\n",
    "            running_loss = total_loss\n",
    "        else:\n",
    "            if(running_loss > total_loss):\n",
    "                running_loss = total_loss\n",
    "                torch.save(model.state_dict(), WEIGHTPATH)\n",
    "        print(f\"Training loss: {total_loss} in Epoch: {epoch+1}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc12af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    device = GetDevice()\n",
    "    num_correct = 0\n",
    "    num_seen = 0\n",
    "    model.load_state_dict(torch.load(WEIGHTPATH))\n",
    "    model.eval()\n",
    "    sm = nn.Softmax(dim = 1)\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "            imgs,  label = batch\n",
    "            imgs = imgs.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(imgs)\n",
    "            pred = sm(outputs)\n",
    "            pred = torch.argmax(pred, dim=1).item()\n",
    "            num_seen += len(label)\n",
    "            if(pred == label.item()):\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                pass\n",
    "    acc = (num_correct/num_seen) * 100\n",
    "    print(f\"Validation Accuracy: {acc:.2f} %\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d48eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to datasets/CIFAR100/train/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029163837432861328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 169001437,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d8a8358c043ba9e8872beff7a6d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/CIFAR100/train/cifar-100-python.tar.gz to datasets/CIFAR100/train/\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to datasets/CIFAR100/val/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03461170196533203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 169001437,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4982cfdf73c947929dfbe2a0b74a104b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169001437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/CIFAR100/val/cifar-100-python.tar.gz to datasets/CIFAR100/val/\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader = CifarData().get_data_loader(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "496303ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet50.parameters(),\n",
    "                      lr=0.0001, eps=1e-08,)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea586f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 131.85928010940552 in Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 113.65455293655396 in Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 109.42681884765625 in Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 104.64359188079834 in Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 99.30416560173035 in Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 94.30466389656067 in Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 88.97371625900269 in Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 83.52443623542786 in Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 77.59175729751587 in Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 71.03951263427734 in Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 63.44356441497803 in Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 56.490001916885376 in Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 48.44175124168396 in Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 40.8328959941864 in Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 32.73275446891785 in Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 25.558336973190308 in Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 19.781832695007324 in Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 13.847102791070938 in Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:08<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.194314062595367 in Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.138386845588684 in Epoch: 20\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(resnet50, optimizer, trainloader, 20, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0d0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 50000/50000 [07:34<00:00, 110.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 99.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.166"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(resnet50, valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saliency_calibration",
   "language": "python",
   "name": "saliency_calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
